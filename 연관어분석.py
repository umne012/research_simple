import streamlit as st
import pandas as pd
import requests
from io import StringIO
from pyvis.network import Network
import streamlit.components.v1 as components
import json
import tempfile

def show_relation_tab():
    st.title("ğŸ“Œ ì—°ê´€ì–´ ë„¤íŠ¸ì›Œí¬ ë¶„ì„")

    @st.cache_data
    def load_word_and_sentence_data():
        # ğŸ‘‰ ë‹¨ì–´ ì¹´ìš´íŠ¸ ë°ì´í„° (ë³‘í•©ëœ CSV)
        word_url = "https://raw.githubusercontent.com/umne012/research_simple/main/morpheme_word_count_merged.csv"
        word_response = requests.get(word_url)
        word_response.raise_for_status()
        word_df = pd.read_csv(StringIO(word_response.text))

        # ğŸ‘‰ ë¸Œëœë“œë³„ë¡œ ë¶„í• 
        word_data = {
            brand: df for brand, df in word_df.groupby("ê·¸ë£¹")
        }

        # ğŸ‘‰ ê°ì • ë¶„ì„ CSV íŒŒíŠ¸ë³„ ë¶ˆëŸ¬ì˜¤ê¸°
        parts = ["part1", "part2", "part3"]
        morph_frames = []
        for part in parts:
            url = f"https://raw.githubusercontent.com/umne012/research_simple/main/morpheme_analysis_{part}.csv"
            response = requests.get(url)
            response.raise_for_status()
            morph_frames.append(pd.read_csv(StringIO(response.text)))

        # ğŸ‘‰ ì „ì²´ ë¬¸ì¥ ë°ì´í„° í•©ì¹˜ê¸°
        sentence_df = pd.concat(morph_frames, ignore_index=True)

        return word_data, sentence_df

    word_data, sentence_df = load_word_and_sentence_data()

    left_col, right_col = st.columns([2, 1])

    with left_col:
        net = Network(height="700px", width="100%", notebook=False, directed=False, bgcolor="#ffffff")
        added_word_nodes = {}
        sentence_map = {}

        for brand, df in word_data.items():
            net.add_node(brand, label=brand, size=30, color="skyblue", shape="box", font={"size": 16})
            word_entries = []
            for _, row in df.iterrows():
                word = row["ë‹¨ì–´"]
                if row.get("positive", 0) > 0:
                    word_entries.append((f"{word}_positive", row["positive"], "positive", word))
                if row.get("negative", 0) > 0:
                    word_entries.append((f"{word}_negative", row["negative"], "negative", word))

            top_entries = sorted(word_entries, key=lambda x: x[1], reverse=True)[:10]

            for node_id, freq, sentiment, word in top_entries:
                node_size = max(20, min(50, freq * 0.5))
                color = "lightcoral" if sentiment == "positive" else "lightblue"

                if node_id not in added_word_nodes:
                    net.add_node(
                        node_id,
                        label=f"{word}\n({sentiment})",
                        size=node_size,
                        color=color,
                        shape="circle",
                        font={"size": 14, "color": "white"},
                        title=f"ì–¸ê¸‰ íšŸìˆ˜: {freq}"
                    )
                    added_word_nodes[node_id] = word

                    matched = sentence_df[(sentence_df["ë‹¨ì–´"] == word) & (sentence_df["ê°ì •"] == sentiment)]
                    sentences = matched[["ë¬¸ì¥ID", "ë‹¨ì–´", "ì›ë³¸ë§í¬"]].drop_duplicates().to_dict("records")
                    sentence_map[node_id] = sentences

                net.add_edge(brand, node_id, weight=freq)

        # âœ… ê³ ìœ í•œ ì„ì‹œíŒŒì¼ì— ì €ì¥ â†’ ìºì‹œ ì¶©ëŒ ë° ë®ì–´ì“°ê¸° ë°©ì§€
        with tempfile.NamedTemporaryFile(delete=False, suffix=".html") as tmp_file:
            net.save_graph(tmp_file.name)
            components.iframe(tmp_file.name, height=750, scrolling=True)

    with right_col:
        st.subheader("ğŸ“ ë‹¨ì–´ ê´€ë ¨ ë¬¸ì¥ ë³´ê¸°")
        st.markdown("ë…¸ë“œë¥¼ í´ë¦­í•˜ë©´ í•´ë‹¹ ë‹¨ì–´ê°€ í¬í•¨ëœ ë¬¸ì¥ì´ ì—¬ê¸°ì— í‘œì‹œë©ë‹ˆë‹¤.")
        st.markdown("<div id='sentence-list'></div>", unsafe_allow_html=True)

        # sentence_mapì„ JSON ë¬¸ìì—´ë¡œ ì „ë‹¬í•˜ê³ , í´ë¦­ëœ nodeIdë¡œ ë¬¸ì¥ ì •ë³´ ë™ì  í‘œì‹œ
        st.components.v1.html(f"""
        <script>
        const sentenceData = {json.dumps(sentence_map)};
        window.addEventListener('message', (e) => {{
            const nodeId = e.data;
            const container = window.parent.document.querySelector('#sentence-list');
            if (!container) return;
            if (sentenceData[nodeId]) {{
                let html = '';
                sentenceData[nodeId].forEach((s, i) => {{
                    html += `<div style='margin-bottom:8px;'>
                        <a href='${{s["ì›ë³¸ë§í¬"]}}' target='_blank'>ğŸ”— ë¬¸ì¥ID: ${{s["ë¬¸ì¥ID"]}} (${{s["ë‹¨ì–´"]}})</a>
                    </div>`;
                }});
                container.innerHTML = html;
            }}
        }});
        </script>
        """, height=0)
