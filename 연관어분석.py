def show_relation_tab():
    import streamlit as st
    import pandas as pd
    import requests
    import plotly.graph_objects as go
    from io import StringIO
    import json
    import base64

    st.markdown("""
    <link href="https://cdn.jsdelivr.net/npm/pretendard@1.3.8/dist/web/static/pretendard.css" rel="stylesheet">
    <style>
        html, body, [class^="css"] {
            font-family: 'Pretendard', sans-serif !important;
        }
    </style>
""", unsafe_allow_html=True)
    st.title("ğŸ“Œ ì—°ê´€ì–´ ë¶„ì„")

    weeks = {
        "3ì›” 1ì£¼ì°¨ ('25.3.1~3.7)": "2025_03w1",
        "3ì›” 2ì£¼ì°¨ ('25.3.8~3.14)": "2025_03w2",
        "3ì›” 3ì£¼ì°¨ ('25.3.15~3.21)": "2025_03w3"
    }
    selected_label = st.selectbox("ğŸ“‚ ì£¼ì°¨ ì„ íƒ", list(weeks.keys()), index=0)
    selected_week = weeks[selected_label]

    base_url = f"https://raw.githubusercontent.com/umne012/research_simple/main/{selected_week}"
    word_url = f"{base_url}/morpheme_word_count_merged.csv"
    morph_urls = [f"{base_url}/morpheme_analysis_part{i}.csv" for i in range(1, 4)]
    sentiment_url = f"{base_url}/sentiment_analysis_merged.csv"

    @st.cache_data(show_spinner=False)
    def load_data():
        word_df = pd.read_csv(word_url)
        word_data = {brand: df for brand, df in word_df.groupby("ê·¸ë£¹")}
    
        morph_frames = []
        for url in morph_urls:
            try:
                df = pd.read_csv(url)
                if not df.empty and all(col in df.columns for col in ["ë‹¨ì–´", "ê°ì •", "ë¬¸ì¥ID", "ê·¸ë£¹"]):
                    morph_frames.append(df)
            except Exception as e:
                st.warning(f"âš ï¸ {url} ë¶ˆëŸ¬ì˜¤ê¸° ì‹¤íŒ¨: {e}")
        if not morph_frames:
            st.error("âŒ í˜•íƒœì†Œ ë¶„ì„ ë°ì´í„°ê°€ ì—†ê±°ë‚˜ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")
            return None, None, None
    
        morph_df = pd.concat(morph_frames, ignore_index=True)
        morph_df = morph_df.merge(word_df[["ë‹¨ì–´", "ê·¸ë£¹"]].drop_duplicates(), on="ë‹¨ì–´", how="left")
    
        try:
            sent_df = pd.read_csv(sentiment_url)
            sent_df.columns = sent_df.columns.str.strip()  # âœ… KeyError ë°©ì§€ìš©
        except Exception as e:
            st.error(f"sentiment_analysis_merged.csv ë¶ˆëŸ¬ì˜¤ê¸° ì˜¤ë¥˜: {e}")
            return None, None, None
    
        morph_df["ë¬¸ì¥ID"] = morph_df["ë¬¸ì¥ID"].astype(str)
        sent_df["ë¬¸ì¥ID"] = sent_df["ë¬¸ì¥ID"].astype(str)
    
        return word_data, morph_df, sent_df
        
    

    word_data, morph_df, sent_df = load_data()

    st.write("ğŸ“Œ morph_df columns:", morph_df.columns.tolist()

    
    if word_data is None:
        return

    # âœ… ë‹¤ìš´ë¡œë“œìš© ë°ì´í„° êµ¬ì„±
    export_rows = []
    for brand, df in word_data.items():
        word_entries = []
        for _, row in df.iterrows():
            word = row["ë‹¨ì–´"]
            if row.get("positive", 0) > 0:
                word_entries.append((word, row["positive"], "positive"))
            if row.get("negative", 0) > 0:
                word_entries.append((word, row["negative"], "negative"))

        top_entries = sorted(word_entries, key=lambda x: x[1], reverse=True)[:10]
        for word, freq, sentiment in top_entries:
            match = morph_df[(morph_df["ë‹¨ì–´"] == word) & (morph_df["ê°ì •"] == sentiment) & (morph_df["ê·¸ë£¹"] == brand)]
            matched_ids = match["ë¬¸ì¥ID"].unique()
            matched_sents = sent_df[sent_df["ë¬¸ì¥ID"].isin(matched_ids)]
            for _, row in matched_sents.iterrows():
                export_rows.append({
                    "ë¸Œëœë“œ": brand,
                    "ë‹¨ì–´": word,
                    "ê°ì •": sentiment,
                    "ì–¸ê¸‰íšŸìˆ˜": freq,
                    "ë¬¸ì¥": row["ë¬¸ì¥"],
                    "ë§í¬": row["ì›ë³¸ë§í¬"]
                })

    col1, col2 = st.columns([5, 1])
    with col1:
        st.markdown(f"### ğŸ“‚ {selected_label}")
    with col2:
        if export_rows:
            export_df = pd.DataFrame(export_rows)
            from io import BytesIO
            towrite = BytesIO()
            export_df.to_csv(towrite, index=False, encoding="cp949")
            towrite.seek(0)
            b64 = base64.b64encode(towrite.read()).decode()
            href = f"<a href='data:file/csv;base64,{b64}' download='{selected_week}_ì—°ê´€ì–´_ë¬¸ì¥.csv'>ğŸ“¥</a>"
            st.markdown(f"<div style='text-align:right;font-size:24px;padding-top:25px'>{href}</div>", unsafe_allow_html=True)

    # (ì¤‘ëµ - ë„¤íŠ¸ì›Œí¬ ê·¸ë˜í”„ ë° ì„ ê·¸ë˜í”„ ì¶œë ¥ì€ ê·¸ëŒ€ë¡œ ìœ ì§€)
    st.markdown("\n")




    nodes, links, added_words = [], [], set()
    sentence_map = {}
    link_counter = {}

    def highlight_and_shorten(text, keyword):
        if keyword not in text:
            return text[:50] + "..." if len(text) > 50 else text
        idx = text.index(keyword)
        start = max(0, idx - 15)
        end = min(len(text), idx + len(keyword) + 15)
        snippet = text[start:end]
        if start > 0:
            snippet = "..." + snippet
        if end < len(text):
            snippet += "..."
        return snippet.replace(keyword, f"<b style='background:yellow'>{keyword}</b>")

    for brand, df in word_data.items():
        nodes.append({"id": brand, "group": "brand"})
        word_entries = []
        for _, row in df.iterrows():
            word = row["ë‹¨ì–´"]
            if row.get("positive", 0) > 0:
                word_entries.append((f"{word}_positive", row["positive"], "positive", word))
            if row.get("negative", 0) > 0:
                word_entries.append((f"{word}_negative", row["negative"], "negative", word))
        top_entries = sorted(word_entries, key=lambda x: x[1], reverse=True)[:10]
        for node_id, freq, sentiment, word in top_entries:
            if node_id not in added_words:
                nodes.append({"id": node_id, "group": sentiment, "freq": freq})
                added_words.add(node_id)
    
                match = morph_df[
                    (morph_df["ë‹¨ì–´"] == word) &
                    (morph_df["ê°ì •"] == sentiment) &
                    (morph_df["ê·¸ë£¹"] == brand)
                ]
                matched_ids = match["ë¬¸ì¥ID"].unique()
                
                matched_sents = sent_df[
                    (sent_df["ë¬¸ì¥ID"].isin(matched_ids)) &
                    (sent_df["ê·¸ë£¹"] == brand)
                ]
    
                shown = []
                for _, row in matched_sents.iterrows():
                    snippet = highlight_and_shorten(str(row["ë¬¸ì¥"]), word)
                    shown.append({
                        "ë¬¸ì¥": snippet,
                        "ì›ë³¸ë§í¬": row["ì›ë³¸ë§í¬"],
                        "count": freq
                    })
                sentence_map[node_id] = shown
    
            links.append({"source": brand, "target": node_id})
            link_counter[node_id] = link_counter.get(node_id, 0) + 1



    nodes_json = json.dumps(nodes)
    links_json = json.dumps(links)
    sentences_json = json.dumps(sentence_map, ensure_ascii=False)

    # âœ… ë„¤íŠ¸ì›Œí¬ ê·¸ë˜í”„ HTML ì§ì ‘ ìƒì„± (ì¤‘ê´„í˜¸ ì´ìŠ¤ì¼€ì´í”„ ìˆ˜ì •)
    html_code = f"""
    <!DOCTYPE html>
    <html lang=\"ko\">
    <head>
    <meta charset=\"UTF-8\">
    <style>
    body {{ display: flex; font-family: Arial, sans-serif; }}
    svg {{ width: 75%; height: 600px; border: 1px solid #ccc; }}
    #sentence-panel {{ width: 25%; padding: 10px; background: #f9f9f9; border-left: 1px solid #ddd; overflow-y: auto; height: 600px; }}
    h3 {{ margin-top: 0; font-size: 16px; }}
    .text-link {{ margin-bottom: 8px; display: block; font-size: 13px; }}
    </style>
    <script src=\"https://d3js.org/d3.v7.min.js\"></script>
    </head>
    <body>
    <svg></svg>
    <div id=\"sentence-panel\">
        <h3>ğŸ“ ê´€ë ¨ ë¬¸ì¥ <span id='count-label' style='font-size:13px; color:gray'></span></h3>
        <div id=\"sentences\">ë…¸ë“œë¥¼ í´ë¦­í•´ë³´ì„¸ìš”.</div>
    </div>
    <script>
    const nodes = {nodes_json};
    const links = {links_json};
    const sentenceData = {sentences_json};

    const width = document.querySelector("svg").clientWidth;
    const height = document.querySelector("svg").clientHeight;
    const svg = d3.select("svg");

    const simulation = d3.forceSimulation(nodes)
        .force("link", d3.forceLink(links).id(d => d.id).distance(80))
        .force("charge", d3.forceManyBody().strength(-100))
        .force("center", d3.forceCenter(width / 2, height / 2));

    const linkCount = {{}};
    links.forEach(l => {{
        linkCount[l.target] = (linkCount[l.target] || 0) + 1;
    }});

    const link = svg.append("g")
        .selectAll("line")
        .data(links)
        .enter().append("line")
        .attr("stroke", "#aaa")
        .attr("stroke-width", 2)
        .attr("stroke-dasharray", d => linkCount[d.target] > 1 ? "0" : "4,4");

    const node = svg.append("g")
        .selectAll("g")
        .data(nodes)
        .enter().append("g")
        .call(d3.drag()
            .on("start", dragstarted)
            .on("drag", dragged)
            .on("end", dragended));

    node.append("circle")
        .attr("r", d => d.freq ? Math.max(15, Math.min(50, d.freq * 0.03)) : 30)
        .attr("fill", d => {{
            if (d.group === "positive") return "#ADD8E6";
            if (d.group === "negative") return "#FA8072";
            return "#FFD700";
        }})
        .attr("stroke", "#333")
        .attr("stroke-width", 2)
        .attr("stroke-dasharray", "4,2");

    node.append("text")
        .attr("dy", "0.35em")
        .attr("text-anchor", "middle")
        .attr("font-size", "11px")
        .text(d => d.id.replace("_positive", "").replace("_negative", ""));

    node.on("click", (event, d) => {{
        const panel = document.getElementById("sentences");
        const counter = document.getElementById("count-label");
        const data = sentenceData[d.id];
        if (!data || data.length === 0) {{
            panel.innerHTML = "<i>ê´€ë ¨ ë¬¸ì¥ì´ ì—†ìŠµë‹ˆë‹¤.</i>";
            counter.innerHTML = "";
            return;
        }}
        panel.innerHTML = data.map(s => `
            <a class="text-link" href="${{s['ì›ë³¸ë§í¬']}}" target="_blank">
                ${{s['ë¬¸ì¥']}}
            </a>
        `).join("");
        counter.innerHTML = `(ì–¸ê¸‰íšŸìˆ˜: ${{data[0].count}}íšŒ)`;
    }});

    simulation.on("tick", () => {{
        link.attr("x1", d => d.source.x)
            .attr("y1", d => d.source.y)
            .attr("x2", d => d.target.x)
            .attr("y2", d => d.target.y);
        node.attr("transform", d => `translate(${{d.x}},${{d.y}})`);
    }});

    function dragstarted(event, d) {{
        if (!event.active) simulation.alphaTarget(0.3).restart();
        d.fx = d.x;
        d.fy = d.y;
    }}

    function dragged(event, d) {{
        d.fx = event.x;
        d.fy = event.y;
    }}

    function dragended(event, d) {{
        if (!event.active) simulation.alphaTarget(0);
        d.fx = null;
        d.fy = null;
    }}
    </script>
    </body>
    </html>
    """

    st.components.v1.html(html_code, height=650)

    # âœ… ì„ ê·¸ë˜í”„ (Plotly Graph Object ë°©ì‹)
    st.markdown("### ğŸ“Š ì¼ìë³„ ì–¸ê¸‰ëŸ‰ ì¶”ì´")
    if sent_df is not None and "ë‚ ì§œ" in sent_df.columns and "ì›ë³¸ë§í¬" in sent_df.columns and "ê·¸ë£¹" in sent_df.columns:
        mention_daily = sent_df.groupby(["ë‚ ì§œ", "ê·¸ë£¹"])["ì›ë³¸ë§í¬"].nunique().reset_index(name="ì–¸ê¸‰ëŸ‰")

        layout = go.Layout(
            plot_bgcolor="#ffffff",
            paper_bgcolor="#ffffff",
            title=dict(text="ì¼ìë³„ ë¸Œëœë“œ ì–¸ê¸‰ëŸ‰ ì¶”ì´", x=0.05, font=dict(size=18)),
            margin=dict(l=40, r=40, t=60, b=100),
            xaxis=dict(title="ë‚ ì§œ", showgrid=True, tickangle=-45),
            yaxis=dict(title="ì–¸ê¸‰ëŸ‰", showgrid=True),
            legend=dict(orientation="h", x=0.5, y=-0.3, xanchor="center", yanchor="top")
        )

        fig = go.Figure(layout=layout)
        for group, df in mention_daily.groupby("ê·¸ë£¹"):
            fig.add_trace(go.Scatter(
                x=df["ë‚ ì§œ"],
                y=df["ì–¸ê¸‰ëŸ‰"],
                mode="lines+markers",
                name=group
            ))

        st.plotly_chart(fig, use_container_width=True)
    else:
        st.info("ğŸ“Œ ì¼ìë³„ ì–¸ê¸‰ëŸ‰ì„ ì‹œê°í™”í•˜ë ¤ë©´ sentiment_analysis.csvì— 'ë‚ ì§œ', 'ê·¸ë£¹' ì»¬ëŸ¼ì´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.")
