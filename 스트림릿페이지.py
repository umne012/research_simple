import streamlit as st
from datetime import date, timedelta
import requests
import plotly.graph_objects as go
from streamlit_option_menu import option_menu
from streamlit_tags import st_tags
from io import BytesIO
import pandas as pd
import json
from pyvis.network import Network
import streamlit.components.v1 as components
import time

st.set_page_config(layout="wide")

# âœ… ì „ì²´ ìŠ¤íƒ€ì¼ ì ìš©
st.markdown("""
    <style>
    * {
        font-family: 'Pretendard', sans-serif;
    }

    /* ğŸ” ë¶„ì„ ë²„íŠ¼ (ë¶‰ì€ ê°•ì¡°) - ì²« ë²ˆì§¸ st.button */
    div.stButton:nth-of-type(1) > button {
        background-color: transparent;
        color: #FA8072;
        padding: 7px 24px;
        border: 1px dashed #FA8072;
        border-radius: 6px;
        font-size: 16px;
        width: 100%;
        cursor: pointer;
        transition: all 0.3s ease;
    }
    div.stButton:nth-of-type(1) > button:hover {
        background-color: #FA8072;
        color: white;
        border: 1px solid #FA8072;
    }

    /* ğŸ“„ PDF ì €ì¥ ë²„íŠ¼ (hover ì´ˆë¡ ê°•ì¡°) */
    button.pdf-btn {
        background-color: transparent;
        color: #4CAF50;
        padding: 7px 24px;
        border: 1px dashed #4CAF50;
        border-radius: 6px;
        font-size: 16px;
        width: 100%;
        cursor: pointer;
        transition: all 0.3s ease;
    }
    button.pdf-btn:hover {
        background-color: #4CAF50;
        color: white;
        border: 1px solid #4CAF50;
    }
    </style>
""", unsafe_allow_html=True)


# âœ… ì‚¬ì´ë“œ ë©”ë‰´
with st.sidebar:
    selected_tab = option_menu(
        menu_title="research",
        options=["ê²€ìƒ‰íŠ¸ë Œë“œ", "ì—°ê´€ì–´ ë¶„ì„", "ê¸ë¶€ì • ë¶„ì„"],
        icons=["bar-chart", "graph-up", "emoji-smile"],
        menu_icon="cast",
        default_index=0,
    )

# âœ… ì´ˆê¸° ê·¸ë£¹
original_search_groups = [
    {"groupName": "Skylife", "keywords": ["ìŠ¤ì¹´ì´ë¼ì´í”„", "skylife"], "exclude": []},
    {"groupName": "KT", "keywords": ["KT", "ì¼€ì´í‹°", "ê¸°ê°€ì§€ë‹ˆ", "ì§€ë‹ˆí‹°ë¹„"], "exclude": ["SKT", "M ëª¨ë°”ì¼"]},
    {"groupName": "SKB", "keywords": ["skb", "ë¸Œë¡œë“œë°´ë“œ", "btv", "ë¹„í‹°ë¹„", "bí‹°ë¹„"], "exclude": []},
    {"groupName": "LGU", "keywords": ["LGU+", "ìœ í”ŒëŸ¬ìŠ¤", "ìœ í”Œ"], "exclude": []},
]

if "search_groups" not in st.session_state:
    st.session_state.search_groups = original_search_groups.copy()

search_groups = st.session_state.search_groups

if selected_tab == "ê²€ìƒ‰íŠ¸ë Œë“œ":
    st.title("ê²€ìƒ‰íŠ¸ë Œë“œ ë¶„ì„")

    # âœ… ê²€ìƒ‰ì–´/ì œì™¸ì–´ ì„¤ì •
    with st.expander("ğŸ“‹ ê·¸ë£¹ë³„ ê²€ìƒ‰ì–´/ì œì™¸ì–´ ì„¤ì •", expanded=False):
        group_inputs = {}
        for group in original_search_groups:
            st.markdown(f"<h5 style='color: #333;'>{group['groupName']}</h5>", unsafe_allow_html=True)
            kw_tags = st_tags(label="ê²€ìƒ‰ì–´", text="ì—”í„°ë¡œ ì—¬ëŸ¬ ê°œ ë“±ë¡", value=group["keywords"], key=f"kw_{group['groupName']}")
            ex_tags = st_tags(label="ì œì™¸ì–´", text="ì—”í„°ë¡œ ì—¬ëŸ¬ ê°œ ë“±ë¡", value=group["exclude"], key=f"ex_{group['groupName']}")
            group_inputs[group["groupName"]] = {"keywords": kw_tags, "exclude": ex_tags}

        if st.button("ğŸ” ì„¤ì • ì ìš©", key="apply_button"):
            st.session_state.search_groups = [
                {"groupName": name, "keywords": values["keywords"], "exclude": values["exclude"]}
                for name, values in group_inputs.items()
            ]
            search_groups = st.session_state.search_groups

    # âœ… ë‚ ì§œ ì„ íƒ
    today = date.today()
    default_start = today - timedelta(days=7)
    default_end = today

    col1, col2, col3, col4 = st.columns([2.1, 2.1, 1, 1])
    with col1:
        start_date = st.date_input("ì‹œì‘ì¼", value=default_start)
    with col2:
        end_date = st.date_input("ì¢…ë£Œì¼", value=default_end)

    # âœ… ë¶„ì„ ì‹œì‘ ë²„íŠ¼ â†’ rerun ì—†ì´ ë°”ë¡œ ì‹¤í–‰
    with col3:
        st.markdown("<div style='padding-top: 28px;'>", unsafe_allow_html=True)
        run_analysis = st.button("ğŸ” ë¶„ì„ ì‹œì‘", key="run_button")
        st.markdown("</div>", unsafe_allow_html=True)

    # âœ… PDF ì €ì¥ ë²„íŠ¼
    with col4:
        st.markdown("""
            <div style='padding-top: 28px;'>
                <button onclick="window.print()" class="pdf-btn">
                    ğŸ“„ PDF ì €ì¥
                </button>
            </div>
        """, unsafe_allow_html=True)



    # âœ… run_analysis í´ë¦­ ì‹œ ë¶„ì„ ìˆ˜í–‰
    if run_analysis:
        def get_date_range(start, end):
            return [(start + timedelta(days=i)).isoformat() for i in range((end - start).days + 1)]

        date_range = get_date_range(start_date, end_date)

        trend_data = {}
        try:
            response = requests.post(
                "https://openapi.naver.com/v1/datalab/search",
                headers={
                    "X-Naver-Client-Id": st.secrets["NAVER_CLIENT_ID"],
                    "X-Naver-Client-Secret": st.secrets["NAVER_CLIENT_SECRET"],
                    "Content-Type": "application/json",
                },
                json={
                    "startDate": str(start_date),
                    "endDate": str(end_date),
                    "timeUnit": "date",
                    "keywordGroups": [
                        {"groupName": g["groupName"], "keywords": g["keywords"]} for g in search_groups
                    ],
                },
            )
            if response.ok:
                trend_data = response.json()
                st.session_state.trend_data = trend_data
            else:
                st.error(f"ê²€ìƒ‰ íŠ¸ë Œë“œ ì˜¤ë¥˜: {response.status_code}")
        except Exception as e:
            st.error(f"API ìš”ì²­ ì‹¤íŒ¨: {e}")

        mention_data = {"labels": date_range, "datasets": []}
        group_mentions = {g["groupName"]: [] for g in search_groups}

        with st.spinner("ğŸ“° ë‰´ìŠ¤Â·ë¸”ë¡œê·¸ ì–¸ê¸‰ëŸ‰ ìˆ˜ì§‘ ì¤‘..."):
            for group in search_groups:
                values = []
                for d in date_range:
                    exclude_query = " ".join([f"-{word}" for word in group.get("exclude", [])])
                    total_mentions = 0
                    for keyword in group["keywords"]:
                        full_query = f"{keyword} {exclude_query} {d}"
                        for endpoint in ["news.json", "blog.json"]:
                            try:
                                res = requests.get(
                                    f"https://openapi.naver.com/v1/search/{endpoint}",
                                    headers={
                                        "X-Naver-Client-Id": st.secrets["NAVER_CLIENT_ID_2"],
                                        "X-Naver-Client-Secret": st.secrets["NAVER_CLIENT_SECRET_2"],
                                    },
                                    params={"query": full_query, "display": 5, "start": 1, "sort": "date"},
                                )
                                if res.ok:
                                    total_mentions += res.json().get("total", 0)
                                    for item in res.json().get("items", []):
                                        group_mentions[group["groupName"]].append({
                                            "title": item["title"].replace("<b>", "").replace("</b>", ""),
                                            "link": item["link"]
                                        })
                            except:
                                pass
                    values.append(total_mentions)
                mention_data["datasets"].append({"label": group["groupName"], "data": values})

        st.session_state.mention_data = mention_data
        st.session_state.group_mentions = group_mentions

    # âœ… ì‹œê°í™”
    trend_data = st.session_state.get("trend_data", {})
    mention_data = st.session_state.get("mention_data", {})
    group_mentions = st.session_state.get("group_mentions", {})

    if trend_data and mention_data:
        st.subheader("ê²€ìƒ‰ëŸ‰ ë° ì–¸ê¸‰ëŸ‰ ê·¸ë˜í”„")
        gcol1, gcol2 = st.columns(2)

        layout = go.Layout(
            plot_bgcolor="#ffffff",
            paper_bgcolor="#ffffff",
            title=dict(x=0.05, font=dict(size=18)),
            margin=dict(l=40, r=40, t=60, b=100),
            xaxis=dict(title="ë‚ ì§œ", showgrid=True),
            yaxis=dict(title="ê°’", showgrid=True),
            legend=dict(
                orientation="h",
                x=0.5,
                y=-0.2,
                xanchor="center",
                yanchor="top"
            )
        )

        with gcol1:
            fig = go.Figure(layout=layout)
            fig.update_layout(title="ë„¤ì´ë²„ ê²€ìƒ‰ëŸ‰")
            for group in trend_data.get("results", []):
                fig.add_trace(go.Scatter(
                    x=[d["period"] for d in group["data"]],
                    y=[d["ratio"] for d in group["data"]],
                    mode="lines+markers",
                    name=group["title"]
                ))
            st.plotly_chart(fig, use_container_width=True)

        with gcol2:
            fig2 = go.Figure(layout=layout)
            fig2.update_layout(title="ë‰´ìŠ¤Â·ë¸”ë¡œê·¸ ì–¸ê¸‰ëŸ‰")
            for ds in mention_data.get("datasets", []):
                fig2.add_trace(go.Scatter(
                    x=mention_data.get("labels", []),
                    y=ds["data"],
                    mode="lines+markers",
                    name=ds["label"]
                ))
            st.plotly_chart(fig2, use_container_width=True)

        st.subheader("ì‹¤ì‹œê°„ ë‰´ìŠ¤Â·ë¸”ë¡œê·¸ ë¬¸ì¥ ë¦¬ìŠ¤íŠ¸")
        cols = st.columns(4)
        for idx, group in enumerate(search_groups):
            with cols[idx % 4]:
                st.markdown(f"<h4 style='text-align:center; color:#0366d6'>{group['groupName']}</h4>", unsafe_allow_html=True)
                for item in group_mentions.get(group['groupName'], [])[:10]:
                    st.markdown(f'''
                    <div style='border:1px solid #eee; padding:10px; margin-bottom:8px; border-radius:8px; background-color:#fafafa;'>
                        <a href="{item['link']}" target="_blank" style="text-decoration:none; color:#333; font-weight:500;">
                            ğŸ”— {item['title']}
                        </a>
                    </div>
                    ''', unsafe_allow_html=True)


# âœ… ì—°ê´€ì–´ ë¶„ì„ íƒ­
elif selected_tab == "ì—°ê´€ì–´ ë¶„ì„":
    st.title("ğŸ“Œ ì—°ê´€ì–´ ë„¤íŠ¸ì›Œí¬ ë¶„ì„")

    @st.cache_data
    def load_word_and_sentence_data():
        word_url = "https://raw.githubusercontent.com/umne012/research_simple/main/morpheme_word_count.xlsx"
        morph_url = "https://raw.githubusercontent.com/umne012/research_simple/main/morpheme_analysis.xlsx"

        word_response = requests.get(word_url)
        morph_response = requests.get(morph_url)

        word_response.raise_for_status()
        morph_response.raise_for_status()

        word_xls = pd.ExcelFile(BytesIO(word_response.content), engine="openpyxl")
        word_data = {
            sheet: pd.read_excel(word_xls, sheet_name=sheet, engine="openpyxl")
            for sheet in word_xls.sheet_names
        }

        morph_df = pd.read_excel(BytesIO(morph_response.content), sheet_name=None, engine="openpyxl")
        all_sentences = pd.concat(morph_df.values(), ignore_index=True)

        return word_data, all_sentences

    word_data, sentence_df = load_word_and_sentence_data()
    left_col, right_col = st.columns([2, 1])
    with left_col:
        net = Network(height="700px", width="100%", notebook=False, directed=False, bgcolor="#ffffff")
        added_word_nodes = {}
        sentence_map = {}

        for brand, df in word_data.items():
            net.add_node(brand, label=brand, size=30, color="skyblue", shape="box", font={"size": 16})
            word_entries = []
            for _, row in df.iterrows():
                word = row["ë‹¨ì–´"]
                if row.get("positive", 0) > 0:
                    word_entries.append((f"{word}_positive", row["positive"], "positive", word))
                if row.get("negative", 0) > 0:
                    word_entries.append((f"{word}_negative", row["negative"], "negative", word))

            top_entries = sorted(word_entries, key=lambda x: x[1], reverse=True)[:10]

            for node_id, freq, sentiment, word in top_entries:
                node_size = max(20, min(50, freq * 0.5))
                color = "lightcoral" if sentiment == "positive" else "lightblue"

                if node_id not in added_word_nodes:
                    net.add_node(
                        node_id,
                        label=f"{word}\n({sentiment})",
                        size=node_size,
                        color=color,
                        shape="circle",
                        font={"size": 14, "color": "white"},
                        title=f"ì–¸ê¸‰ íšŸìˆ˜: {freq}"
                    )
                    added_word_nodes[node_id] = word
                    matched = sentence_df[(sentence_df["ë‹¨ì–´"] == word) & (sentence_df["ê°ì •"] == sentiment)]
                    sentences = matched[["ë¬¸ì¥ID", "ë‹¨ì–´", "ì›ë³¸ë§í¬"]].drop_duplicates().to_dict("records")
                    sentence_map[node_id] = sentences

                net.add_edge(brand, node_id, weight=freq)

        net.force_atlas_2based(gravity=-50, central_gravity=0.02, spring_length=20, spring_strength=0.8)
        net.save_graph("network_graph.html")
        components.iframe("network_graph.html", height=750, scrolling=True)

    with right_col:
        st.subheader("ğŸ“ ë‹¨ì–´ ê´€ë ¨ ë¬¸ì¥ ë³´ê¸°")
        st.markdown("ë…¸ë“œë¥¼ í´ë¦­í•˜ë©´ í•´ë‹¹ ë‹¨ì–´ê°€ í¬í•¨ëœ ë¬¸ì¥ì´ ì—¬ê¸°ì— í‘œì‹œë©ë‹ˆë‹¤.")
        st.markdown("<div id='sentence-list'></div>", unsafe_allow_html=True)

        st.components.v1.html(f"""
        <script>
        const sentenceData = {json.dumps(sentence_map)};
        window.addEventListener('message', (e) => {{
            const nodeId = e.data;
            const container = window.parent.document.querySelector('#sentence-list');
            if (!container) return;
            if (sentenceData[nodeId]) {{
                let html = '';
                sentenceData[nodeId].forEach((s, i) => {{
                    html += `<div style='margin-bottom:8px;'>
                        <a href='${{s["ì›ë³¸ë§í¬"]}}' target='_blank'>ğŸ”— ë¬¸ì¥ID: ${{s["ë¬¸ì¥ID"]}} (${{s["ë‹¨ì–´"]}})</a>
                    </div>`;
                }});
                container.innerHTML = html;
            }}
        }});
        </script>
        """, height=0)

# âœ… ê¸ë¶€ì • ë¶„ì„ íƒ­
elif selected_tab == "ê¸ë¶€ì • ë¶„ì„":
    st.title("ğŸ™‚ ê¸Â·ë¶€ì • ë¶„ì„ (ê°œë°œ ì˜ˆì •)")
    st.info("ì´ íƒ­ì€ ì¤€ë¹„ ì¤‘ì…ë‹ˆë‹¤.")
